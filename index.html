<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Physically Plausible Full-Body Hand-Object Interaction Synthesis.">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Physically Plausible Full-Body Hand-Object Interaction Synthesis</title>

  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-72PW1FZDE4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-72PW1FZDE4');
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Physically Plausible Full-Body Hand-Object Interaction Synthesis</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Jona Braun</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/sammyc">Sammy Christen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ps.is.tuebingen.mpg.de/person/mkocabas">Muhammed Kocabas</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/eaksan">Emre Aksan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/hilliges">Otmar Hilliges</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of Computer Science, ETH Zurich, Switzerland</span>
            <br>
            <span class="author-block"><sup>2</sup>Max Planck Institute for Intelligent Systems, TÃ¼bingen, Germany</span>
            <br>
            <span class="author-block">  <b>In International Conference on 3D Vision 2024 (3DV) </b></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2309.07907.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=um7p3WpD8zI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/eth-ait/phys-fullbody-grasp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <!-- Teaser. -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="diagram">
          <img src="static/images/teaser.png" alt="Teaser"/>
            </div>
        </div>
    </div>
  </div>
  <!--/ Teaser. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose a physics-based method for synthesizing dexterous hand-object interactions in a full-body setting. While recent advancements have addressed specific facets of human-object interactions, a comprehensive physics-based approach remains a challenge. Existing methods often focus on isolated segments of the interaction process and rely on data-driven techniques that may result in artifacts. In contrast, our proposed method embraces reinforcement learning (RL) and physics simulation to mitigate the limitations of data-driven approaches. Through a hierarchical framework, we first learn skill priors for both body and hand movements in a decoupled setting. The generic skill priors learn to decode a latent skill embedding into the motion of the underlying part. A high-level policy then controls hand-object interactions in these pretrained latent spaces, guided by task objectives of grasping and 3D target trajectory following. It is trained using a novel reward function that combines an adversarial style term with a task reward, encouraging natural motions while fulfilling the task incentives. Our method successfully accomplishes the complete interaction task, from approaching an object to grasping and subsequent manipulation. We compare our approach against kinematics-based baselines and show that it leads to more physically plausible motions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section_video">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video id="teaser" controls height="100%">
            <source src="https://files.ait.ethz.ch/projects/phys-fullbody-grasp/phys_fullbody_grasp_video.mp4" type="video/mp4">
          </video>
        </div>
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{braun2023physically,
      title={Physically Plausible Full-Body Hand-Object Interaction Synthesis},
      author={Jona Braun and Sammy Christen and Muhammed Kocabas and Emre Aksan and Otmar Hilliges},
      booktitle={International Conference on 3D Vision (3DV)},
      year={2024}
}   </code></pre>
  </div>
</section>

</body>
</html>
